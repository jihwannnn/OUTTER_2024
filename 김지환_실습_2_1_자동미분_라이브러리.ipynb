{"cells":[{"cell_type":"markdown","id":"25533d3b","metadata":{"id":"25533d3b"},"source":["# 실습 3: 자동미분(AutoDiff) 라이브러리"]},{"cell_type":"markdown","id":"f60968f6","metadata":{"id":"f60968f6"},"source":["앞서 우리는 그래디언트 기반 학습에 대해 살펴보았다. $\\mathscr{L}$이 간단한 함수일 때는 편미분하는 것이 간단한 일이었지만, 앞으로는 손으로 편미분을 계산하기는 어려운 다양한 함수들을 $\\mathscr{L}$ 로 만나게 될 것이다. 이럴 때 필요한 것이 바로 컴퓨터의 계산 능력이다. 그래디언트 기반 학습에 대한 관심이 크게 증가하면서, 미분을 자동으로 계산해주는 자동미분 라이브러리가 여럿 개발되었다. 널리 쓰이는 라이브러리로는 [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax), [Zygote](https://github.com/FluxML/Zygote.jl) 등이 있다.\n","\n","이 책에서는 위의 라이브러리 중에서 쉽게 이해하고 사용할 수 있는 PyTorch 라이브러리를 사용할 것이다. 이 라이브러리는 NumPy 라이브러리와 매우 유사하게 동작하기 때문에, NumPy만 잘 알아도 쉽게 사용할 수 있다. NumPy에서 ndarray(배열)가 기본이 되는 핵심 객체인 것과 같이, PyTorch의 핵심 객체는 Tensor(텐서)라고 부른다. 이 Tensor는 ndarray와 매우 유사하게 동작이 가능하다.\n","\n","이 실습에서 PyTorch를 통한 자동미분에 익숙해지고 나면, 이 책 전반에 걸쳐 PyTorch를 자유자재로 사용하며 딥러닝을 배우게 될 것이다."]},{"cell_type":"code","execution_count":2,"id":"e93acc4d","metadata":{"id":"e93acc4d","executionInfo":{"status":"ok","timestamp":1720445869709,"user_tz":-540,"elapsed":4444,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["import torch\n","import torch as tc\n","import numpy as np"]},{"cell_type":"markdown","id":"03d35d08","metadata":{"id":"03d35d08"},"source":["구글 코랩(Google Colab)에서는 PyTorch가 기본적으로 설치되어 있다. 따라서 별도로 설치할 필요 없이 바로 사용 가능하다. PyTorch가 제대로 설치되어 있는지 확인하려면 아래와 같은 코드를 실행해볼 수 있다.\n","torch.cuda.is_available() 코드가 False의 결과가 나오면 메뉴에서\n","\n","런타임 > 런타임 유형 변경 > 하드웨어 가속기\n","\n","에서 보면 CPU가 선택되어 있을 것인데 이를 GPU로 바꿔줘야 한다."]},{"cell_type":"code","execution_count":3,"id":"kPxSBddWT2OT","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kPxSBddWT2OT","outputId":"598eab57-e529-4c86-bc74-5f4a00910c19","executionInfo":{"status":"ok","timestamp":1720445872432,"user_tz":-540,"elapsed":605,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2.3.0+cu121\n","True\n"]}],"source":["print(torch.__version__)\n","print(torch.cuda.is_available())"]},{"cell_type":"markdown","id":"a73926ed","metadata":{"id":"a73926ed"},"source":["### Step 1. PyTorch의 여러가지 함수"]},{"cell_type":"markdown","id":"335815d5","metadata":{"id":"335815d5"},"source":["라이브러리를 사용할 때, 유명한 라이브러리의 경우에는 구글링을 통해 쉽게 설명된 블로그 등을 참고할 수도 있다. 하지만 정석은 라이브러리 개발자가 작성한 도큐먼트(document)를 읽는 것이다. 이 실습에서는 PyTorch를 사용한 자동미분을 배우는 것을 가장 중요한 목적으로 다루고 있으므로, 더 다양한 함수와 기능이 궁금하다면 직접 [도큐먼트](https://mygrad.readthedocs.io/en/latest/)를 읽어보길 바란다. 또한, NumPy의 기본 함수들과 일치하는 함수를 많이 가지고 있으므로, NumPy의 함수들을 찾아 PyTorch에 적용해보아도 좋다."]},{"cell_type":"markdown","id":"d06b0a0d","metadata":{"id":"d06b0a0d"},"source":["#### Tensor 생성\n","Tensor는 Pytorch 라이브러리에서 사용하는 데이터를 배열 형식으로 저장하도록 한다. 다양한 방식으로 Tensor를 생성할 수 있다. 다음은 Tensor를 생성하는 여러 가지 예이다. tc.tensor 외에도 Tensor를 생성하는 다양한 함수들이 있다. 직접 코드를 실행하여 output을 확인해보자."]},{"cell_type":"code","execution_count":5,"id":"42d2424d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42d2424d","outputId":"26a026d7-d946-4479-8fc4-7efc1e90cedb","executionInfo":{"status":"ok","timestamp":1720446119285,"user_tz":-540,"elapsed":552,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.3000)"]},"metadata":{},"execution_count":5}],"source":["# 단일 숫자로 생성한 Tensor\n","tc.tensor(2.3)"]},{"cell_type":"code","execution_count":7,"id":"4b71a705","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4b71a705","outputId":"7c12b554-bb82-473f-b5c6-fd5ea90f469d","executionInfo":{"status":"ok","timestamp":1720446169981,"user_tz":-540,"elapsed":622,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 2., 3.])"]},"metadata":{},"execution_count":7}],"source":["# 시퀀스(리스트, 튜플 등) 자료형으로 생성한 Tensor.\n","# dtype을 지정할 수 있는 모든 함수에서\n","# 32-bit floats를 저장하는 텐서를 반환하도록 지정 가능.\n","tc.tensor([1.0, 2.0, 3.0], dtype=tc.float32)"]},{"cell_type":"code","execution_count":9,"id":"737f62f3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"737f62f3","outputId":"26e41a67-db0f-40bc-9b68-c695b437561d","executionInfo":{"status":"ok","timestamp":1720446208277,"user_tz":-540,"elapsed":748,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)"]},"metadata":{},"execution_count":9}],"source":["# numpy.ndarray로부터 생성한 Tensor\n","arr = np.ones((3,3))\n","tc.tensor(arr)"]},{"cell_type":"code","execution_count":15,"id":"970b3585","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"970b3585","outputId":"9f483ec8-a20b-444e-8687-da509eb412a3","executionInfo":{"status":"ok","timestamp":1720446337892,"user_tz":-540,"elapsed":527,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]],\n","\n","        [[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]]])\n","tensor([[[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]],\n","\n","        [[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]])\n"]}],"source":["# Tensor 생성 함수 (ones, zeros; 각각 1, 0으로 채움)\n","z=tc.zeros((2,3,4))\n","o=tc.ones((2,3,4))\n","print(z)\n","print(o)"]},{"cell_type":"code","execution_count":16,"id":"dbe81f6c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbe81f6c","outputId":"228a158e-6ea0-4414-c127-4c49eb55bb4b","executionInfo":{"status":"ok","timestamp":1720446384215,"user_tz":-540,"elapsed":538,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-5, -3, -1,  1,  3,  5,  7,  9, 11, 13])"]},"metadata":{},"execution_count":16}],"source":["# Tensor 생성 함수 (start 부터 stop 까지 step 만큼 띄워가며 채움)\n","tc.arange(-5, 15, 2)"]},{"cell_type":"code","execution_count":17,"id":"ae113b63","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae113b63","outputId":"1ace8b66-becd-4a06-ef3f-59d946f4e727","executionInfo":{"status":"ok","timestamp":1720446402723,"user_tz":-540,"elapsed":531,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])"]},"metadata":{},"execution_count":17}],"source":["# start = 0, step = 1이 default 값\n","tc.arange(9)"]},{"cell_type":"code","execution_count":18,"id":"fbdb971e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbdb971e","outputId":"d710b8c0-0fc7-4dc2-ff68-a9592e617b28","executionInfo":{"status":"ok","timestamp":1720446435801,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.6642, 0.9030, 0.6890, 0.3904],\n","        [0.4145, 0.3497, 0.7713, 0.4555],\n","        [0.6667, 0.8265, 0.3873, 0.9967]])"]},"metadata":{},"execution_count":18}],"source":["# 0~1 사이의 값 무작위로 리턴 (확률분포는 균등분포(uniform))\n","tc.rand(3, 4)"]},{"cell_type":"markdown","id":"9373be2a","metadata":{"id":"9373be2a"},"source":["<문제: 주어진 조건을 만족하는 Tensor 생성하기>\n","\n","구간 $[0, \\pi]$에 등간격으로 분포한 15개의 구성요소로 이루어진 shape-(15,)인 tensor를 만들어보자. (Hint: tc.linspace(), tc.pi)"]},{"cell_type":"code","execution_count":20,"id":"82ebd43d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82ebd43d","outputId":"fe39c423-f8fd-49b1-b010-82e8771eeb7c","scrolled":false,"executionInfo":{"status":"ok","timestamp":1720446610038,"user_tz":-540,"elapsed":545,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.2244, 0.4488, 0.6732, 0.8976, 1.1220, 1.3464, 1.5708, 1.7952,\n","        2.0196, 2.2440, 2.4684, 2.6928, 2.9172, 3.1416])"]},"metadata":{},"execution_count":20}],"source":["# 여기에 코드 작성\n","tc.linspace(0, tc.pi, 15)"]},{"cell_type":"markdown","id":"71697cae","metadata":{"id":"71697cae"},"source":["#### Tensor 변형\n","Tensor의 모양을 변형하는 함수들도 있다. 직접 코드를 실행하여 output을 확인해보자."]},{"cell_type":"code","execution_count":23,"id":"38946f50","metadata":{"id":"38946f50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720446824939,"user_tz":-540,"elapsed":523,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"53c34e28-bc72-4e87-942a-6c288844d9af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0, 1, 2],\n","        [3, 4, 5],\n","        [6, 7, 8]])"]},"metadata":{},"execution_count":23}],"source":["# Tensor의 행과 열을 바꾸어주는 함수\n","x = tc.arange(9) #Tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])\n","x.reshape(3,3)"]},{"cell_type":"code","execution_count":25,"id":"3a22b453","metadata":{"id":"3a22b453","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720446939340,"user_tz":-540,"elapsed":592,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"76545f0f-4115-441d-e79a-54d3840fc254"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1, 3, 5],\n","        [2, 4, 6]])"]},"metadata":{},"execution_count":25}],"source":["# Tensor의 전치 행렬을 구하는 함수\n","x = tc.tensor([[1, 2], [3, 4], [5, 6]])\n","x.t()"]},{"cell_type":"code","execution_count":28,"id":"a38b3441","metadata":{"id":"a38b3441","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447016095,"user_tz":-540,"elapsed":612,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"7acd753c-4936-42a4-9b75-7864d4b64906"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3, 4, 5])"]},"metadata":{},"execution_count":28}],"source":["# 슬라이싱 (자유자재로 쓸 수 있으면 좋다)\n","x=tc.tensor([[1,2,3,4,5], [6,7,8,9,10]])\n","x[0,2:]"]},{"cell_type":"code","execution_count":30,"id":"6320c0ee","metadata":{"id":"6320c0ee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447055945,"user_tz":-540,"elapsed":566,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"3a1c2bba-344e-4564-e398-c348ed3d74e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3, 4, 5])"]},"metadata":{},"execution_count":30}],"source":["x[0,-3:]"]},{"cell_type":"markdown","id":"6232d6c1","metadata":{"id":"6232d6c1"},"source":["#### Tensor 표준 수학 연산\n","\n","먼저, PyTorch에서 제공하는 표준적인 수학 함수들을 알아보자. 기본적인 산술 연산을 하는 함수를 비롯하여, (sum, mean, var, std, max, min) 등의 통계량을 구하는 함수 등이 제공된다. 또한, 삼각함수, 쌍곡함수, 지수함수, 로그함수 등의 초월함수도 제공된다. NumPy의 함수들과 동일하게, 벡터화된 함수들이다.\n","\n","단항 함수는 텐서에 대해 요소별로 각각 작동한다. 이항 함수는 두 텐서에 대해 대응되는 위치의 요소 간에 자연스럽게 작동한다. 두 텐서가 동일한 모양이 아니더라도 Numpy와 같은 [브로드캐스팅(Broadcasting)](https://numpy.org/doc/stable/user/basics.broadcasting.html) 규칙을 따르기 때문에, 이항 함수가 작동할 수 있는 경우가 있다.\n","\n","직접 코드를 실행하여 output을 확인해보자. 이를 통해 단항 연산과 이항 연산을 다루는 여러 함수에 대해 이해해보자."]},{"cell_type":"code","execution_count":47,"id":"b4d930c8","metadata":{"id":"b4d930c8","executionInfo":{"status":"ok","timestamp":1720447538917,"user_tz":-540,"elapsed":543,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["x = tc.tensor([0.0, 0.25, 0.5, 0.75, 1.0])\n","y = tc.tensor([[0.],[1.],[2.]])\n","z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])"]},{"cell_type":"code","execution_count":33,"id":"aa53ba6b","metadata":{"id":"aa53ba6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447171302,"user_tz":-540,"elapsed":703,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"1cb0a044-42c8-4d20-a7da-9bcff578776e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.2474, 0.4794, 0.6816, 0.8415])"]},"metadata":{},"execution_count":33}],"source":["# 단항 함수 중 하나인 삼각함수 sin()\n","# 텐서의 모든 요소의 sin 값으로 채워진 같은 크기의 텐서\n","tc.sin(x)"]},{"cell_type":"code","execution_count":34,"id":"27891022","metadata":{"id":"27891022","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447196552,"user_tz":-540,"elapsed":704,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"c122be11-c0b5-4867-faa8-64c8d7f8ce81"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(66)"]},"metadata":{},"execution_count":34}],"source":["# 단항 함수 중 통계량을 구하는 함수들은 axis 인자를 가짐\n","# axis가 0이면 행에 대해서만 함수를 적용하고,\n","# axis가 1이면 열에 대해서만 함수를 적용\n","tc.sum(z)"]},{"cell_type":"code","execution_count":36,"id":"99ed2ce2","metadata":{"id":"99ed2ce2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447226552,"user_tz":-540,"elapsed":584,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"209a3bcc-e438-4f89-f496-4c9896f12595"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 6, 22, 38])"]},"metadata":{},"execution_count":36}],"source":["tc.sum(z, axis=1)"]},{"cell_type":"markdown","id":"628e8b1b","metadata":{"id":"628e8b1b"},"source":["z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])\n","\n","=>\n","\n","$[[0,1,2,3], \\\\\n","    [4,5,6,7], \\\\\n","    [8,9,10,11]]$"]},{"cell_type":"code","execution_count":null,"id":"9fe0294b","metadata":{"id":"9fe0294b"},"outputs":[],"source":["강의의 코드를 직접 타이핑해보세요."]},{"cell_type":"code","execution_count":37,"id":"b9686434","metadata":{"id":"b9686434","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447289825,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"1396a310-be2b-4ae3-d323-9d58d58a24b1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n","        [1.0000, 1.2500, 1.5000, 1.7500, 2.0000],\n","        [2.0000, 2.2500, 2.5000, 2.7500, 3.0000]])"]},"metadata":{},"execution_count":37}],"source":["# 브로드캐스팅 예(1)\n","# x+y, y+z는 브로드캐스팅이 가능, x+z는 불가능\n","x+y"]},{"cell_type":"code","execution_count":43,"id":"6c0e5310","metadata":{"id":"6c0e5310","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447505758,"user_tz":-540,"elapsed":545,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"3fac9fc2-a82b-40a1-e28b-ef4f79c3c315"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  1.,  2.,  3.],\n","        [ 5.,  6.,  7.,  8.],\n","        [10., 11., 12., 13.]])"]},"metadata":{},"execution_count":43}],"source":["y+z"]},{"cell_type":"code","execution_count":39,"id":"ef7e7090","metadata":{"id":"ef7e7090","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"error","timestamp":1720447374257,"user_tz":-540,"elapsed":4,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"994ad1c5-e1eb-4b7e-d918-ac2639ba4365"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-0e52b3dd32a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"]}],"source":["x+z # Error 발생"]},{"cell_type":"code","execution_count":40,"id":"942ebf93","metadata":{"id":"942ebf93","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447401617,"user_tz":-540,"elapsed":3,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"81fba090-7c49-41d5-e2b6-6ebe8f8f12fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n","        [0.0000, 0.5000, 1.0000, 1.5000, 2.0000]])"]},"metadata":{},"execution_count":40}],"source":["# 브로드캐스팅 예(2)\n","# x*y, y*z는 브로드캐스팅이 가능, x*z는 불가능\n","x*y"]},{"cell_type":"code","execution_count":48,"id":"45b61b7f","metadata":{"id":"45b61b7f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447544945,"user_tz":-540,"elapsed":845,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"3691dbd2-0c4e-4f0c-b02c-6580a993c75b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  0.,  0.,  0.],\n","        [ 4.,  5.,  6.,  7.],\n","        [16., 18., 20., 22.]])"]},"metadata":{},"execution_count":48}],"source":["y*z"]},{"cell_type":"code","execution_count":42,"id":"6b613e37","metadata":{"id":"6b613e37","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"error","timestamp":1720447406538,"user_tz":-540,"elapsed":3,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"ffb286cc-d9ab-448a-827e-571ce80c8410"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-babf0bcfe656>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"]}],"source":["x*z # Error 발생"]},{"cell_type":"markdown","id":"ad45aec1","metadata":{"id":"ad45aec1"},"source":["<문제: Pytorch의 기본 수학 연산>\n","\n","아래와 같이 정의된 텐서 x에 대해 여러 가지 수학 연산을 적용하여 여러 가지 텐서를 구해보자."]},{"cell_type":"code","execution_count":49,"id":"a98929d0","metadata":{"id":"a98929d0","executionInfo":{"status":"ok","timestamp":1720447572312,"user_tz":-540,"elapsed":733,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["x = tc.Tensor([[ 0.,  1.,  2.,  3.],\n","...                [ 4.,  5.,  6.,  7.],\n","...                [ 8.,  9., 10., 11.],\n","...                [12., 13., 14., 15.]])"]},{"cell_type":"markdown","source":["## 1번 문제"],"metadata":{"id":"prqrJypdiwJ2"},"id":"prqrJypdiwJ2"},{"cell_type":"markdown","id":"6e03887e","metadata":{"id":"6e03887e"},"source":["1. x의 3행의 첫번째, 세번째 원소에 대한 자연로그 값으로 채워진 shape-(2,)인 Tensor를 구해보자."]},{"cell_type":"code","execution_count":56,"id":"7b89e057","metadata":{"id":"7b89e057","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447708675,"user_tz":-540,"elapsed":528,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"90073b43-6285-4fbf-dff7-a69d6a30f3d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2.0794, 2.3026])"]},"metadata":{},"execution_count":56}],"source":["# 여기에 코드 작성\n","tc.log(x[2, 0::2])"]},{"cell_type":"markdown","id":"3d1e928f","metadata":{"id":"3d1e928f"},"source":["## 1번 문제 정답"]},{"cell_type":"code","source":["tc.log(x[2,0::2])"],"metadata":{"id":"2wSGga_FiWIq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447673190,"user_tz":-540,"elapsed":550,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"8c918d1b-b510-421c-da2f-b4da56c526f6"},"id":"2wSGga_FiWIq","execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2.0794, 2.3026])"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["1번 문제 출력 결과 : tensor([2.0794, 2.3026])"],"metadata":{"id":"F7fzgO9kikUX"},"id":"F7fzgO9kikUX"},{"cell_type":"markdown","source":["# 2번 문제"],"metadata":{"id":"6M3xaJomisFT"},"id":"6M3xaJomisFT"},{"cell_type":"markdown","id":"65c19bdd","metadata":{"id":"65c19bdd"},"source":["2. x를 가로, 세로로 4등분한 각 귀퉁이(왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래)의 4개 원소를 더하여 shape-(2,2)인 Tensor를 구해보자."]},{"cell_type":"code","execution_count":61,"id":"b0076def","metadata":{"id":"b0076def","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447854550,"user_tz":-540,"elapsed":697,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"a62cd528-30a3-4391-dd7a-df29b3b45ec2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[20., 24.],\n","        [36., 40.]])"]},"metadata":{},"execution_count":61}],"source":["# 여기에 코드 작성\n","x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"]},{"cell_type":"markdown","source":["## 2번 문제 정답"],"metadata":{"id":"AyY6znLKidQj"},"id":"AyY6znLKidQj"},{"cell_type":"code","source":["x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"],"metadata":{"id":"a3JavlrAi3Nn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447842760,"user_tz":-540,"elapsed":564,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"7c77e522-e409-4759-f99b-30f2e500ba9a"},"id":"a3JavlrAi3Nn","execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[20., 24.],\n","        [36., 40.]])"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","source":["2번 문제 출력 결과 :\n","\n","tensor([[20., 24.],\\\n","        [36., 40.]])"],"metadata":{"id":"2ZYKqDfmjKFu"},"id":"2ZYKqDfmjKFu"},{"cell_type":"markdown","source":["## 3번 문제"],"metadata":{"id":"t8AcEm9Ni-9i"},"id":"t8AcEm9Ni-9i"},{"cell_type":"markdown","id":"d18ec6e0","metadata":{"id":"d18ec6e0"},"source":["  3. x의 각 열의 평균을 구하여 shape-(4,)인 Tensor를 구해보자."]},{"cell_type":"code","execution_count":62,"id":"5ff6a6bc","metadata":{"id":"5ff6a6bc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447909471,"user_tz":-540,"elapsed":544,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"e9b48b19-5143-4ab4-8e34-f521382c1b01"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([6., 7., 8., 9.])"]},"metadata":{},"execution_count":62}],"source":["# 여기에 코드 작성\n","x.mean(axis=0)"]},{"cell_type":"markdown","source":["## 3번 문제 정답"],"metadata":{"id":"Mf_Q1BkEjoCf"},"id":"Mf_Q1BkEjoCf"},{"cell_type":"code","source":["x.mean(axis=0)"],"metadata":{"id":"-pmoGU-0jnk5"},"id":"-pmoGU-0jnk5","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3번 문제 출력 결과 : tensor([6., 7., 8., 9.])"],"metadata":{"id":"Pn-E0xyKjobv"},"id":"Pn-E0xyKjobv"},{"cell_type":"markdown","source":["# 4번 문제"],"metadata":{"id":"W7y-HGgwjzr7"},"id":"W7y-HGgwjzr7"},{"cell_type":"markdown","id":"d29b6965","metadata":{"id":"d29b6965"},"source":["4. x의 각 행을 벡터로보고, 각 벡터가 크기가 1이 되도록 정규화하여 shape-(4,4)인 Tensor로 업데이트해보자."]},{"cell_type":"code","execution_count":64,"id":"57234e34","metadata":{"id":"57234e34","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720448014747,"user_tz":-540,"elapsed":3,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"7582c0d5-9dac-4f60-8279-b1b1f7c9aa46"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0000, 0.2673, 0.5345, 0.8018],\n","        [0.3563, 0.4454, 0.5345, 0.6236],\n","        [0.4182, 0.4704, 0.5227, 0.5750],\n","        [0.4429, 0.4798, 0.5167, 0.5537]])"]},"metadata":{},"execution_count":64}],"source":["# 여기에 코드 작성\n","x/= tc.sqrt(tc.sum(x**2,axis=1,keepdims = True))\n","x"]},{"cell_type":"code","execution_count":null,"id":"d038eb54","metadata":{"id":"d038eb54"},"outputs":[],"source":["# 정규화가 잘 되었는지 확인하기\n"]},{"cell_type":"markdown","source":["## 4번 문제 정답"],"metadata":{"id":"-zPuP1PPj_yj"},"id":"-zPuP1PPj_yj"},{"cell_type":"code","source":["x /= tc.sqrt(tc.sum(x**2,axis=1,keepdims = True))\n","x"],"metadata":{"id":"hZ_679jyj3rQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720447963147,"user_tz":-540,"elapsed":554,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"c606cfb1-8e11-4cb0-df4f-13e0af24bc9d"},"id":"hZ_679jyj3rQ","execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0000, 0.2673, 0.5345, 0.8018],\n","        [0.3563, 0.4454, 0.5345, 0.6236],\n","        [0.4182, 0.4704, 0.5227, 0.5750],\n","        [0.4429, 0.4798, 0.5167, 0.5537]])"]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","source":["4번 문제 출력 결과 : \\\\\n","\n","tensor([[0.0000, 0.2673, 0.5345, 0.8018], \\\n","        [0.3563, 0.4454, 0.5345, 0.6236], \\\n","        [0.4182, 0.4704, 0.5227, 0.5750], \\\n","        [0.4429, 0.4798, 0.5167, 0.5537]])"],"metadata":{"id":"dVP8WS0PkDKT"},"id":"dVP8WS0PkDKT"},{"cell_type":"code","source":["# 정규화가 잘 되었는지 확인하기 정답\n","(x**2).sum(axis=1)"],"metadata":{"id":"J9xPBjRsj3ff"},"id":"J9xPBjRsj3ff","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#   "],"metadata":{"id":"n8GyohNmkccZ"},"id":"n8GyohNmkccZ"},{"cell_type":"markdown","id":"ca7b8e69","metadata":{"id":"ca7b8e69"},"source":["#### 선형대수 연산 함수"]},{"cell_type":"markdown","id":"47ce788e","metadata":{"id":"47ce788e"},"source":["PyTorch에는 선형대수 연산을 쉽게 계산하도록 도와주는 함수들도 있다. matmul()은 행렬곱을 계산해주는 함수이다. 이를 이용하여 벡터의 점곱(스칼라곱)을 계산할 수도 있다. einsum()은 아인슈타인 표기법(Einstein notation 또는 Einstein summation convention)을 계산하는 함수이다. 이는 다소 복잡한 함수이지만, 다양한 사용자 지정 가능한 선형 대수 연산을 수행할 수 있다. PyTorch가 자동미분을 수행할 때 이 연산들을 통해 수행한다."]},{"cell_type":"markdown","id":"171b9c09","metadata":{"id":"171b9c09"},"source":["먼저 이항 연산 함수인 matmul()연산은 행렬곱을 기본으로 하는 함수이므로 2차원 텐서 간의 연산이 가장 자연스럽게 정의된다. 1차원 텐서 간의 matmul()을 명령하면 1차원 텐서를 1xn 크기의 2차원 텐서로 생각하여 연산을 진행한다. 그리고 n차원(3차원 이상)의 텐서 간의 matmul()은 n-2차원의 텐서의 구성요소가 2차원 텐서(행렬)인 것으로 생각하여 연산을 진행한다. 즉, 행렬이 여러개 모여있는 것으로 생각하고 행렬곱을 진행하는 것이다. matmul()연산 또한 NumPy의 브로드캐스팅 규칙을 따르는 함수이기 때문에 3차원 이상의 텐서에 대해서는 브로드캐스팅에도 유의해야 한다.\n","\n","matmul()을 사용할 때는 tc.matmul(x,y)로 사용할 수 있지만, x @ y 와 같이 연산자 @를 이용하여도 같은 연산을 할 수 있도록 정의되어 있다. 아래의 사용 예시를 따라가면 matmul() 함수의 사용법을 이해할 수 있을 것이다. 직접 코드를 실행하여 output을 확인해보자."]},{"cell_type":"code","execution_count":65,"id":"c0d89dcb","metadata":{"id":"c0d89dcb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720448130302,"user_tz":-540,"elapsed":533,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"ef2dbf3b-d50c-472f-d699-013fef743001"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-11.)"]},"metadata":{},"execution_count":65}],"source":["# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n","x = tc.tensor([1.0, 2.0])\n","y = tc.tensor([-3.0, -4.0])\n","tc.matmul(x, y)"]},{"cell_type":"code","source":["# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n","x = tc.tensor([1.0, 2.0])\n","y = tc.tensor([-3.0, -4.0])\n","tc.matmul(x, y)"],"metadata":{"id":"oKmJhLeklBTI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720448167524,"user_tz":-540,"elapsed":573,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"cc1ec8d5-d013-40c4-f4f8-e3e088bd7083"},"id":"oKmJhLeklBTI","execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-11.)"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","execution_count":67,"id":"594d0ad6","metadata":{"id":"594d0ad6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720448195905,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"ecbe12d0-502d-48fc-b540-d6d5ec635d60"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 4,  1,  5],\n","        [ 2,  2,  6],\n","        [10,  4, 16],\n","        [20, 11, 39]])"]},"metadata":{},"execution_count":67}],"source":["# 2차원 텐서의 matmul 연산은 그냥 행렬곱과 같음\n","a = tc.tensor([[1, 0], [0, 1], [2, 1], [3, 4]])\n","b = tc.tensor([[4, 1, 5], [2, 2, 6]])\n","tc.matmul(a,b)"]},{"cell_type":"code","execution_count":69,"id":"375463a3","metadata":{"id":"375463a3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720448532271,"user_tz":-540,"elapsed":670,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"ccfe355a-6b0a-455a-9a70-cec5dc148093"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0,  1,  2],\n","         [ 3,  4,  5]],\n","\n","        [[ 2,  3,  4],\n","         [ 5,  6,  7]],\n","\n","        [[ 4,  5,  6],\n","         [ 7,  8,  9]],\n","\n","        [[ 6,  7,  8],\n","         [ 9, 10, 11]]])\n","tensor([[[ 0,  1,  2],\n","         [ 3,  4,  5],\n","         [ 6,  7,  8]],\n","\n","        [[ 3,  4,  5],\n","         [ 6,  7,  8],\n","         [ 9, 10, 11]],\n","\n","        [[ 6,  7,  8],\n","         [ 9, 10, 11],\n","         [12, 13, 14]],\n","\n","        [[ 9, 10, 11],\n","         [12, 13, 14],\n","         [15, 16, 17]]])\n","tensor([[[ 15,  18,  21],\n","         [ 42,  54,  66]],\n","\n","        [[ 60,  69,  78],\n","         [114, 132, 150]],\n","\n","        [[141, 156, 171],\n","         [222, 246, 270]],\n","\n","        [[258, 279, 300],\n","         [366, 396, 426]]])\n"]}],"source":["# A는 크기가 (4, 2, 3)인 3차원 텐서\n","A1= tc.arange(2*3).reshape(2,3)\n","A = tc.stack([A1,A1+2,A1+4,A1+6])\n","\n","# B는 크기가 (4, 3, 3)인 3차원 텐서\n","B1= tc.arange(3*3).reshape(3,3)\n","B = tc.stack([B1,B1+2,B1+4,B1+6])\n","\n","# matmul 연산을 제대로 이해했는지 확인하기 위해\n","# 손으로도 직접 계산해보고, 결과가 동일한지 확인해보기\n","print(A)\n","print(B)\n","print(tc.matmul(A, B))"]},{"cell_type":"code","execution_count":70,"id":"6479f8f0","metadata":{"id":"6479f8f0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720449042441,"user_tz":-540,"elapsed":759,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"41948c0d-1378-4c86-f1a2-9181803ecc2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 2, 3])\n","tensor([[[ 15,  18,  21],\n","         [ 42,  54,  66]],\n","\n","        [[ 60,  69,  78],\n","         [114, 132, 150]],\n","\n","        [[141, 156, 171],\n","         [222, 246, 270]],\n","\n","        [[258, 279, 300],\n","         [366, 396, 426]]])\n"]}],"source":["C=tc.matmul(A, B)\n","print(C.shape)\n","print(C)"]},{"cell_type":"code","execution_count":72,"id":"e4b01755","metadata":{"id":"e4b01755","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720449090303,"user_tz":-540,"elapsed":541,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"11f14b1b-235b-4107-a536-31c3228760d6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[1.1361, 1.3191],\n","         [1.1838, 1.4021],\n","         [0.6995, 1.1536]],\n","\n","        [[1.6312, 1.2693],\n","         [1.0522, 1.0908],\n","         [1.5214, 1.5538]],\n","\n","        [[1.2519, 0.8329],\n","         [1.4558, 1.0018],\n","         [0.5241, 1.0348]],\n","\n","        [[0.2947, 0.3529],\n","         [1.4261, 1.4745],\n","         [0.7480, 0.2964]],\n","\n","        [[0.6526, 0.6214],\n","         [0.9989, 0.9526],\n","         [0.6020, 0.3713]]])"]},"metadata":{},"execution_count":72}],"source":["# 브로드캐스팅 예 (y를 5개로 브로드캐스팅하여 x와 연산)\n","x = tc.rand(5,3,4)\n","y = tc.rand(4,2)\n","tc.matmul(x, y)"]},{"cell_type":"markdown","id":"7bb78257","metadata":{"id":"7bb78257"},"source":["NumPy에서는 행렬곱 연산을 하는 함수가 두 개 있다. 바로 dot연산과 matmul 연산이다.두 함수는 2차원 배열 두개의 곱에 대해 동일한 행렬곱을 결과로 도출한다. 그러나 3차원 이상에서는 서로 다르게 동작한다. 이 두 함수의 차이가 궁금하다면 직접 검색하여 공부해보자."]},{"cell_type":"markdown","id":"1a3a1d7c","metadata":{"id":"1a3a1d7c"},"source":["다음으로 einsum()함수는 행렬 연산에 관한 다양한 함수들을 다 알지 못하더라도, 이 함수 하나만을 가지고 다양한 행렬 연산을 사용자가 직접 지정해줄 수 있는 함수이다. 이 함수의 원리는 아인슈타인 표기법을 따르는데, 아인슈타인 표기법에 대해 스스로 검색하여 공부해보면 Numpy와 PyTorch에서 einsum()함수를 사용하는 예시들을 쉽게 이해할 수 있을 것이다.\n","\n","아래의 예시들을 직접 실행해보며 einsum()함수의 유용함을 느껴보자, einsum()함수에 대해 완벽히 이해하지 못했더라도 괜찮다. 다만 앞으로 einsum()함수의 새로운 사용 예시를 보게 되더라도 낯설고 어렵게 느끼지 말고, 익숙하게 느끼길 바란다."]},{"cell_type":"code","execution_count":73,"id":"beabda70","metadata":{"id":"beabda70","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720449322085,"user_tz":-540,"elapsed":986,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"4e688edf-1060-442a-b0d4-622011bf613a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0,  1,  2,  3,  4],\n","         [ 5,  6,  7,  8,  9],\n","         [10, 11, 12, 13, 14],\n","         [15, 16, 17, 18, 19],\n","         [20, 21, 22, 23, 24]]),\n"," tensor([[ 0,  1,  2],\n","         [ 3,  4,  5],\n","         [ 6,  7,  8],\n","         [ 9, 10, 11],\n","         [12, 13, 14]]),\n"," tensor([[  0,  -1,  -2],\n","         [ -3,  -4,  -5],\n","         [ -6,  -7,  -8],\n","         [ -9, -10, -11],\n","         [-12, -13, -14]]))"]},"metadata":{},"execution_count":73}],"source":["a = tc.arange(25).reshape(5,5)\n","b = tc.arange(15).reshape(5,3)\n","c = -tc.arange(15).reshape(5,3)\n","a, b, c"]},{"cell_type":"markdown","source":["i는 행, j는 열을 뜻함\n"],"metadata":{"id":"SO5CvLLnsh_n"},"id":"SO5CvLLnsh_n"},{"cell_type":"code","execution_count":75,"id":"c6166eb9","metadata":{"id":"c6166eb9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720449345414,"user_tz":-540,"elapsed":557,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"902176d7-4316-4433-ef1f-6e7754ad0838"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(60)"]},"metadata":{},"execution_count":75}],"source":["# a의 대각합\n","tc.einsum('ii', a)"]},{"cell_type":"code","execution_count":76,"id":"7e81572d","metadata":{"id":"7e81572d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720449380709,"user_tz":-540,"elapsed":580,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"a1470951-cc9e-402b-859c-b9cdfc666ad9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0,  6, 12, 18, 24])"]},"metadata":{},"execution_count":76}],"source":["# a의 대각원소\n","tc.einsum('ii->i',a)"]},{"cell_type":"code","execution_count":81,"id":"bc252f98","metadata":{"id":"bc252f98","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720449563779,"user_tz":-540,"elapsed":569,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"c68b37be-37aa-40ad-c630-126b41dae708"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  3,  6,  9, 12],\n","        [ 1,  4,  7, 10, 13],\n","        [ 2,  5,  8, 11, 14]])"]},"metadata":{},"execution_count":81}],"source":["# b의 전치행렬\n","tc.einsum('ji',b)"]},{"cell_type":"code","execution_count":80,"id":"6d586edc","metadata":{"id":"6d586edc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720449543549,"user_tz":-540,"elapsed":3,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"259dc9fb-01c2-4764-fb13-1c995fa37e70"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 90, 100, 110],\n","        [240, 275, 310],\n","        [390, 450, 510],\n","        [540, 625, 710],\n","        [690, 800, 910]])\n","tensor([[ 90, 100, 110],\n","        [240, 275, 310],\n","        [390, 450, 510],\n","        [540, 625, 710],\n","        [690, 800, 910]])\n"]}],"source":["# a와 b의 행렬곱 계산 (matmul과 결과가 동일함을 확인해보기)\n","s1 = tc.einsum('ij,jk->ik',a,b)\n","s2 = tc.matmul(a,b)\n","print(s1)\n","print(s2)"]},{"cell_type":"code","execution_count":82,"id":"976de1a0","metadata":{"id":"976de1a0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720449611406,"user_tz":-540,"elapsed":545,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"167cd1b1-6896-4322-8215-9ada1217563a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  -5,  -14,  -23,  -32,  -41],\n","        [ -14,  -50,  -86, -122, -158],\n","        [ -23,  -86, -149, -212, -275],\n","        [ -32, -122, -212, -302, -392],\n","        [ -41, -158, -275, -392, -509]])"]},"metadata":{},"execution_count":82}],"source":["# 같은 모양의 텐서 b,c의 각 행끼리의 점곱을 계산\n","tc.einsum('ij,kj->ik',b,c)"]},{"cell_type":"markdown","id":"50bdd8c5","metadata":{"id":"50bdd8c5"},"source":["#### 자동미분과 딥러닝을 위한 특수 함수"]},{"cell_type":"markdown","id":"6676ae0f","metadata":{"id":"6676ae0f"},"source":["PyTorch는 NumPy와 유사한 함수들 외에도 PyTorch만의 딥러닝을 위한 특수 함수들을 제공합니다. torch.nn 모듈에서는 딥러닝을 진행할 신경망을 구현하는 데 필요한 손실 함수(loss function), 활성 함수(activation function), 초기화 함수(initializer)의 대표적인 예시들을 제공합니다. 이러한 함수들에 대해서는 이번 실습에서는 다루지 않을 것이지만, 바로 다음 실습부터 꾸준히 여러 함수들이 등장할 예정입니다."]},{"cell_type":"markdown","id":"e1a37a44","metadata":{"id":"e1a37a44"},"source":["### Step 2 자동미분 실행하기"]},{"cell_type":"markdown","id":"d850545d","metadata":{"id":"d850545d"},"source":["이제 PyTorch 라이브러리의 핵심 기능인 자동미분에 대해 알아보자. PyTorch를 비롯한 대부분의 자동미분 라이브러리는 함수의 도함수(편도함수)를 직접 구하지 않는다. 그 대신 주어진 점(입력값)에서의 미분계수(편미분계수) 값을 구한다. 즉, 자동미분 라이브러리는 지정해준 점에서의 함수의 순간 기울기를 구하는 기능만을 갖고 있으며, 우리는 이를 이용하여 미분가능한 모든 함수의 모든 지점에서의 기울기를 구할 수 있다."]},{"cell_type":"markdown","id":"56abc047","metadata":{"id":"56abc047"},"source":["#### 텐서 객체의 '.backward()' 메서드"]},{"cell_type":"markdown","id":"0e4dd1f7","metadata":{"id":"0e4dd1f7"},"source":["PyTorch에서 자동미분을 호출하기 위해 필요한 유일한 방법은 Tensor.backward()이다. 다른 텐서로부터 계산한 텐서 F에 대해 F.backward()를 호출하면, PyTorch는 F가 의존하는 모든 텐서에 대해 F의 편미분계수를 계산하도록 지시한다. 이 편미분계수들은 각각의 텐서들의 .grad 속성에 Tensor로 저장된다. 이때 몇 가지 주의사항이 있다.\n","\n","1. requires_grad=True:\n","자동 미분을 추적하려면 텐서를 생성할 때 requires_grad=True로 설정해야 한다.\n","\n","2. backward() 호출:\n","Tensor.backward()를 호출하면 해당 텐서로부터 계산된 모든 텐서에 대해 그래디언트(기울기)를 계산합니다. backward()는 스칼라 값에 대해서만 호출할 수 있습니다. 만약 텐서가 스칼라가 아니라면, 적절한 축소 연산을 통해 스칼라로 변환한 후 backward()를 호출해야 한다 (예: sum())."]},{"cell_type":"markdown","id":"ee0edf3a","metadata":{"id":"ee0edf3a"},"source":["예를 들어 아래와 같이 x, y, z 텐서가 있고, x와 y의 함수로 정의된 f 텐서가 있는 상황에서의 편미분을 살펴보자."]},{"cell_type":"code","execution_count":83,"id":"8909fc52","metadata":{"id":"8909fc52","executionInfo":{"status":"ok","timestamp":1720450838859,"user_tz":-540,"elapsed":547,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["x = tc.tensor(2.0, requires_grad=True)\n","y = tc.tensor(3.0, requires_grad=True)\n","z = tc.tensor(4.0, requires_grad=True)\n","f = x * y\n","# tc.multiply(x, y)"]},{"cell_type":"markdown","id":"d9b04f19","metadata":{"id":"d9b04f19"},"source":["이 때, f.backward()를 호출하면 PyTorch가 f의 모든 편미분계수를 계산하도록 지시한다. 이는 역전파(backpropagation)라고 하는 컴퓨터가 빠르게 편미분계수를 계산할 수 있는 알고리즘을 사용하여 수행된다. 역전파 알고리즘은 딥러닝의 발전에서 빠질 수 없는 핵심적인 알고리즘이라 할 수 있는 것으로, 연쇄법칙(chain rule)에 기반한 알고리즘이다."]},{"cell_type":"code","execution_count":84,"id":"eff5c10e","metadata":{"id":"eff5c10e","executionInfo":{"status":"ok","timestamp":1720450851259,"user_tz":-540,"elapsed":565,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["f.backward()"]},{"cell_type":"markdown","id":"a891efdb","metadata":{"id":"a891efdb"},"source":["x와 y의 .grad() 속성을 살펴보면 $\\frac{d F}{d x}$와 $\\frac{d F}{dy}$의 값을 얻을 수 있다. .grad()는 텐서로 구해진다. z는 f가 의존하는 변수 텐서가 아니므로 .grad() 속성에 값이 없다."]},{"cell_type":"code","execution_count":86,"id":"692b2f01","metadata":{"id":"692b2f01","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720450906285,"user_tz":-540,"elapsed":691,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"69cc1095-3917-4deb-8682-9311e88ca08b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3.)"]},"metadata":{},"execution_count":86}],"source":["x.grad"]},{"cell_type":"code","execution_count":87,"id":"208b6de2","metadata":{"id":"208b6de2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720450913127,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"581d7793-6dbf-41fc-b140-0ac881264c89"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.)"]},"metadata":{},"execution_count":87}],"source":["y.grad"]},{"cell_type":"code","execution_count":88,"id":"7d5d2ed2","metadata":{"id":"7d5d2ed2","executionInfo":{"status":"ok","timestamp":1720450926774,"user_tz":-540,"elapsed":571,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["z.grad"]},{"cell_type":"markdown","id":"ab7cd692","metadata":{"id":"ab7cd692"},"source":["이번에는 x, y, 그리고 x와 y로부터 구해지는 f까지 세 텐서에 의존하는 텐서 F의 모든 편미분계수를 계산해보자. 즉, F(f(x, y), x, y)인 경우를 살펴볼 것이다."]},{"cell_type":"code","execution_count":89,"id":"2cebffb7","metadata":{"id":"2cebffb7","executionInfo":{"status":"ok","timestamp":1720451003870,"user_tz":-540,"elapsed":616,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["x = tc.tensor(2.0, requires_grad=True)\n","y = tc.tensor(3.0, requires_grad=True)\n","f = x * y\n","f.retain_grad()\n","F = f+x-y"]},{"cell_type":"code","execution_count":90,"id":"1a90c30f","metadata":{"id":"1a90c30f","executionInfo":{"status":"ok","timestamp":1720451013147,"user_tz":-540,"elapsed":545,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["F.backward()"]},{"cell_type":"markdown","id":"5cb35f93","metadata":{"id":"5cb35f93"},"source":["f의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial f}$의 값을 얻을 수 있다.\n","y의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial y} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial y}$의 값을 얻을 수 있다.\n","\n","마지막으로 x의 경우, t = x에 대해 F = f + t - 2로 쓸 수 있다. 이렇게 생각하고 x의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial x} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial x} + \\frac{\\partial F}{\\partial t}\\frac{\\partial t}{\\partial x}$의 값을 얻을 수 있다.\n","\n","주의사항으로 PyTorch에서 특정 텐서의 그래디언트를 계산하기 위해서는 그 텐서에 대해 직접적으로 requires_grad=True를 설정하고, 필요하다면 중간 텐서에 대해서도 retain_grad() 메소드를 호출해야 한다. retain_grad()는 중간 텐서의 그래디언트를 저장하도록 한다. f.retain_grad() 코드가 없다면 어떻게 실행되는지 확인해보는 것도 좋을 것이다."]},{"cell_type":"code","execution_count":91,"id":"17a4384e","metadata":{"id":"17a4384e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451029114,"user_tz":-540,"elapsed":529,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"014ccc46-1930-4648-f723-b2054c338bf3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":91}],"source":["f.grad"]},{"cell_type":"code","execution_count":92,"id":"c3da1420","metadata":{"id":"c3da1420","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451057358,"user_tz":-540,"elapsed":553,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"644efc6d-3d46-4a0a-a24a-d40edb57b6b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":92}],"source":["x.grad"]},{"cell_type":"code","execution_count":93,"id":"f0f394a3","metadata":{"id":"f0f394a3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451060199,"user_tz":-540,"elapsed":3,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"58ad1ace-850e-47d0-be88-99524c57f861"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":93}],"source":["y.grad"]},{"cell_type":"markdown","id":"06825fb4","metadata":{"id":"06825fb4"},"source":["f와 F가 의존하는 모든 변수들이 PyTorch의 텐서로 저장되어 있었고, f와 F를 이루는 모든 수학적 연산이 PyTorch에서 제공하는 함수였기 때문에 PyTorch를 통해 F의 모든 편미분계수를 구할 수 있었다. 이렇게 구한 편미분계수들로부터 함수의 그래디언트를 이용하는 경사하강법을 쉽게 수행할 수 있다."]},{"cell_type":"markdown","id":"05aac9d3","metadata":{"id":"05aac9d3"},"source":["# 문제: 텐서 객체의 backward() 메서드 사용\n","\n","여러가지 수식으로 정의된 x에 대한 함수 F에 대해, x=2.5에서 $\\frac{d F}{d x}\\big|_{x=2.5}$를 구해보자."]},{"cell_type":"markdown","source":["# 1번 문제"],"metadata":{"id":"MAGBsn7xGd1k"},"id":"MAGBsn7xGd1k"},{"cell_type":"markdown","id":"f35f6a9d","metadata":{"id":"f35f6a9d"},"source":["1. $F(x)=x^2$"]},{"cell_type":"code","execution_count":97,"id":"1ad9f204","metadata":{"id":"1ad9f204","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451358628,"user_tz":-540,"elapsed":553,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"45882d0d-1f91-417a-a627-be3a9921a12e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(5.)"]},"metadata":{},"execution_count":97}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","F = x**2\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 1번 문제 정답"],"metadata":{"id":"xfCuA6MxGEHh"},"id":"xfCuA6MxGEHh"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","F = x**2\n","F.backward()\n","x.grad"],"metadata":{"id":"hA-iU8diGMxo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451347524,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"3a239c38-de5c-4293-b1ba-24268da4664a"},"id":"hA-iU8diGMxo","execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(5.)"]},"metadata":{},"execution_count":96}]},{"cell_type":"markdown","source":["1번 문제 출력 결과 : tensor(5.)"],"metadata":{"id":"YIOuj1FMGPMw"},"id":"YIOuj1FMGPMw"},{"cell_type":"markdown","source":["# 2번 문제"],"metadata":{"id":"ekFW_3OnGSdU"},"id":"ekFW_3OnGSdU"},{"cell_type":"markdown","id":"7a5cd97f","metadata":{"id":"7a5cd97f"},"source":["2. $F(x)=\\cos{\\sqrt{x}}$"]},{"cell_type":"code","execution_count":98,"id":"f62fd0dd","metadata":{"id":"f62fd0dd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451376350,"user_tz":-540,"elapsed":548,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"1d1da0e5-334d-4eee-cce8-a5094d45c1df"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-0.3162)"]},"metadata":{},"execution_count":98}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","F = tc.cos(tc.sqrt(x))\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 2번 문제 정답"],"metadata":{"id":"G1rUUHZFGi-3"},"id":"G1rUUHZFGi-3"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","F = tc.cos(tc.sqrt(x))\n","F.backward()\n","x.grad"],"metadata":{"id":"4V1iRDD3GijE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451380672,"user_tz":-540,"elapsed":590,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"21fdc53c-9714-4597-e580-81a18c9675bd"},"id":"4V1iRDD3GijE","execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-0.3162)"]},"metadata":{},"execution_count":99}]},{"cell_type":"markdown","source":["2번 문제 출력 결과 : tensor(-0.3162)"],"metadata":{"id":"dIrwUZzyGibE"},"id":"dIrwUZzyGibE"},{"cell_type":"markdown","source":["# 3번 문제"],"metadata":{"id":"aBe8aYzXGr3G"},"id":"aBe8aYzXGr3G"},{"cell_type":"markdown","id":"f994e9f9","metadata":{"id":"f994e9f9"},"source":["3. $F(x)=2+3x-5x^2$"]},{"cell_type":"code","execution_count":100,"id":"9aba45f7","metadata":{"id":"9aba45f7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451392961,"user_tz":-540,"elapsed":560,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"1cc55e94-5e2e-485d-e218-88bb8e283ab3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-22.)"]},"metadata":{},"execution_count":100}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","F = 2 + 3*x - 5*x**2\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 3번 문제 정답"],"metadata":{"id":"b-l8ieGVGv3M"},"id":"b-l8ieGVGv3M"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","F = 2+3*x-5*x**2\n","F.backward()\n","x.grad"],"metadata":{"id":"mEgwk9LhGuT6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451396452,"user_tz":-540,"elapsed":547,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"c6da7297-9180-4c36-b068-76174350cb21"},"id":"mEgwk9LhGuT6","execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-22.)"]},"metadata":{},"execution_count":101}]},{"cell_type":"markdown","source":["3번 문제 출력 결과 : tensor(-22.)"],"metadata":{"id":"gOabd2fPGul7"},"id":"gOabd2fPGul7"},{"cell_type":"markdown","source":["# 4번 문제"],"metadata":{"id":"0oTiFRY5G2tE"},"id":"0oTiFRY5G2tE"},{"cell_type":"markdown","id":"aa6ca763","metadata":{"id":"aa6ca763"},"source":["4. $F(x)=e^{lnx}$"]},{"cell_type":"code","execution_count":102,"id":"d028375e","metadata":{"id":"d028375e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451434656,"user_tz":-540,"elapsed":530,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"da8eeb6b-3602-4381-dfa0-c72703f24f0c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":102}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","F = tc.exp(tc.log(x))\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 4번 문제 정답"],"metadata":{"id":"rbGPZ_ydG53A"},"id":"rbGPZ_ydG53A"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","F = tc.exp(tc.log(x))\n","F.backward()\n","x.grad"],"metadata":{"id":"dLQKI_84G5Sa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451439473,"user_tz":-540,"elapsed":636,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"dc7a64c7-eafd-4fde-8748-ed0a3f089609"},"id":"dLQKI_84G5Sa","execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":103}]},{"cell_type":"markdown","source":["4번 문제 출력 결과 : tensor(1.)"],"metadata":{"id":"G49bEx7jG5e4"},"id":"G49bEx7jG5e4"},{"cell_type":"markdown","source":["# 5번 문제"],"metadata":{"id":"9UFMZxcHHEX5"},"id":"9UFMZxcHHEX5"},{"cell_type":"markdown","id":"979502fa","metadata":{"id":"979502fa"},"source":["5. $F(x)=(2xf(x))^2-f(x), f(x)=x^2$"]},{"cell_type":"code","execution_count":104,"id":"e333cb51","metadata":{"id":"e333cb51","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451489101,"user_tz":-540,"elapsed":530,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"cced620f-b5fd-4ad4-a84c-f730a2e49e8b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2338.7500)"]},"metadata":{},"execution_count":104}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","f = x**2\n","f.retain_grad()\n","F = (2*x*f)**2-f\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 5번 문제 정답"],"metadata":{"id":"U0_bPo_AHGKV"},"id":"U0_bPo_AHGKV"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","f = x**2\n","F = (2*x*f)**2-f\n","F.backward()\n","x.grad"],"metadata":{"id":"PmQlhnDvHGbA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451492697,"user_tz":-540,"elapsed":533,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"80e3bab7-9785-45cc-ca90-aa5377fa4c76"},"id":"PmQlhnDvHGbA","execution_count":105,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2338.7500)"]},"metadata":{},"execution_count":105}]},{"cell_type":"markdown","source":["5번 문제 출력 결과 : tensor(2338.7500)"],"metadata":{"id":"mfseKPKcHGwV"},"id":"mfseKPKcHGwV"},{"cell_type":"markdown","source":["# -"],"metadata":{"id":"1wT96P_lHMrw"},"id":"1wT96P_lHMrw"},{"cell_type":"markdown","id":"72ea07a0","metadata":{"id":"72ea07a0"},"source":["#### .grad 속성의 초기화"]},{"cell_type":"markdown","id":"0e8e4d75","metadata":{"id":"0e8e4d75"},"source":["경사하강법을 수행할 때, 텐서와 관련된 편미분계수를 반복적으로 구해야 한다. 따라서, 경사하강을 반복할 때마다 사이사이에 편미분계수를 폐기해야 한다."]},{"cell_type":"markdown","id":"6fce6da3","metadata":{"id":"6fce6da3"},"source":["backward()연산을 진행한 함수가 의존하는 텐서들 중 하나의 .grad 속성을 초기화하는 방법은 다음과 같이 두가지가 있다. 아래와 같은 상황을 생각해보자."]},{"cell_type":"code","execution_count":106,"id":"45b77985","metadata":{"id":"45b77985","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451635559,"user_tz":-540,"elapsed":539,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"d7f154de-b594-4178-9482-62bc67a88ab6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":106}],"source":["x = tc.tensor(2.0, requires_grad=True)\n","f = x**2\n","f.backward()\n","x.grad"]},{"cell_type":"markdown","id":"9b0e92ca","metadata":{"id":"9b0e92ca"},"source":["그래디언트를 초기화하지 않으면, 추가 연산 후 backward()를 호출해도 이전 값에 누적되지 않고 덮어쓴다."]},{"cell_type":"code","execution_count":107,"id":"c7a13d5b","metadata":{"id":"c7a13d5b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451645448,"user_tz":-540,"elapsed":1,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"bc5e1bee-2f74-4501-e7db-61634da7eecd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(8.)"]},"metadata":{},"execution_count":107}],"source":["g = x**2\n","g.backward()\n","x.grad"]},{"cell_type":"markdown","id":"6477d424","metadata":{"id":"6477d424"},"source":["Tensor.grad를 호출하여 해당 텐서의 .grad 속성을 직접적으로 None으로 재설정할 수도 있다."]},{"cell_type":"code","execution_count":108,"id":"71cbc888","metadata":{"id":"71cbc888","executionInfo":{"status":"ok","timestamp":1720451650845,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["x.grad = None"]},{"cell_type":"code","execution_count":109,"id":"0d3fb5eb","metadata":{"id":"0d3fb5eb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451659519,"user_tz":-540,"elapsed":703,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"20efa4de-2f05-420a-840b-44ab8938c4d9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":109}],"source":["x.grad is None"]},{"cell_type":"markdown","id":"6de8423c","metadata":{"id":"6de8423c"},"source":["#### PyTorch와 Numpy의 관계"]},{"cell_type":"markdown","id":"4133bbb6","metadata":{"id":"4133bbb6"},"source":["우리는 앞의 내용에서 PyTorch에서 NumPy의 다양한 수학함수들을 동일하게 정의해두었다는 것을 충분히 확인했다.\n","\n","PyTorch의 텐서 객체는 NumPy 배열과 비교했을 때 별로 새롭지 않다. 텐서 객체는 Numpy 배열에 대한 정보를 기본으로 가지고 있으며, 단지 배열이 관련된 수학적 연산들을 추적하는 추가 역할을 할 뿐이다. 수학적 연산에 대한 추적은 자동미분을 위해 추가된 역할이라고 볼 수 있다.\n","\n","이러한 관계성에 의해 우리는 텐서를 한꺼풀 벗겨내어 NumPy 배열을 얻을 수 있다. 다음의 텐서 x에 대해 NumPy 배열로 만드는 세 가지 방법을 확인해보자."]},{"cell_type":"markdown","id":"7I3HEHz_gIFV","metadata":{"id":"7I3HEHz_gIFV"},"source":["먼저, 기본 텐서의 경우 numpy()를 사용한다."]},{"cell_type":"code","execution_count":111,"id":"55472dc7","metadata":{"id":"55472dc7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451741857,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"7222ed37-28af-48b0-e2fa-005c9605252d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.])"]},"metadata":{},"execution_count":111}],"source":["x = tc.tensor([0.0,1.0,2.0,3.0])\n","x"]},{"cell_type":"code","execution_count":112,"id":"1ef96a8b","metadata":{"id":"1ef96a8b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451744531,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"b6315e5f-1321-42ff-cbb4-d67d9ba88bae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1., 2., 3.], dtype=float32)"]},"metadata":{},"execution_count":112}],"source":["x.numpy()"]},{"cell_type":"markdown","id":"9e22945e","metadata":{"id":"9e22945e"},"source":["두번째로, grad 정보가 포함된 경우 detach().numpy()를 사용한다."]},{"cell_type":"code","execution_count":113,"id":"ac022abd","metadata":{"id":"ac022abd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451751963,"user_tz":-540,"elapsed":891,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"12ea6ab9-ad04-4c8c-a8a2-eff1d397714d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.], requires_grad=True)"]},"metadata":{},"execution_count":113}],"source":["x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True)\n","x"]},{"cell_type":"code","execution_count":114,"id":"38a70485","metadata":{"id":"38a70485","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451758760,"user_tz":-540,"elapsed":550,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"e703da6a-4078-482e-87aa-ab5870b2fb77"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1., 2., 3.], dtype=float32)"]},"metadata":{},"execution_count":114}],"source":["x.detach().numpy()"]},{"cell_type":"markdown","id":"CqdEZEnAg9p9","metadata":{"id":"CqdEZEnAg9p9"},"source":["세번째로, gpu에 선언된 텐서의 경우 cpu().numpy()를 사용한다."]},{"cell_type":"code","execution_count":115,"id":"uwST0Z-7g596","metadata":{"id":"uwST0Z-7g596","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451769253,"user_tz":-540,"elapsed":1460,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"692bf2d1-7ae1-4594-a5da-caa39260e917"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.], device='cuda:0', grad_fn=<ToCopyBackward0>)"]},"metadata":{},"execution_count":115}],"source":["x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True).cuda()\n","x"]},{"cell_type":"code","execution_count":117,"id":"2wax3zVOhMkf","metadata":{"id":"2wax3zVOhMkf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451794073,"user_tz":-540,"elapsed":532,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"28b5d628-f36f-477f-adf3-273b111bfb4b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1., 2., 3.], dtype=float32)"]},"metadata":{},"execution_count":117}],"source":["x.cpu().detach().numpy()"]},{"cell_type":"markdown","id":"61fa582a","metadata":{"id":"61fa582a"},"source":["#### 편미분계수 계산 시 상수 텐서와 변수 텐서"]},{"cell_type":"markdown","id":"364ca3a4","metadata":{"id":"364ca3a4"},"source":["앞서 살펴본 머신러닝 모델에 대해 경사하강법을 진행하는 경우를 생각해보자.\n","\n","머신러닝 모델을 다음과 같이 정의할 때\n","\\begin{equation}\n","\\mathscr{L}\\big(w_1, ..., w_M ; (x_n, y_n)_{n=0}^{N-1}\\big)\n","\\end{equation}\n","\n","경사하강법을 수행하기 위해 우리는 $\\frac{d\\mathscr{L}}{dw_i}$를 각각의 $w_i$에 대해 계산해야 한다. 그러나, $\\frac{d\\mathscr{L}}{dx_i}$는 필요하지 않다. 특히, 입력 데이터셋이 크고 복잡해질수록, 필요없는 수많은 편미분계수를 일일이 계산하는 것은 쓸데없이 많은 비용이 드는 일이다.\n","\n","위에서 배운대로라면, PyTorch 텐서의 .backward() 메서드는 $\\mathscr{L}$를 이루는 모든 변수 텐서들에 대해 편미분계수를 계산한다. 따라서, 우리는 편미분계수 계산이 필요없는 데이터들을 변수 텐서가 아니라 상수 텐서로 표현함으로써 자동으로 .backward() 계산에서 배제되도록 할 것이다. 상수 텐서로 취급할 수 있는 방법을 알아보자."]},{"cell_type":"markdown","id":"667de722","metadata":{"id":"667de722"},"source":["PyTorch의 텐서 객체를 생성할 때 requires_grad=False를 사용하여 상수 텐서를 생성할 수 있다. requires_grad=False로 설정된 텐서는 그래디언트 계산에 포함되지 않는다. 기본값이 requires_grad=False이므로, 특별히 지정하지 않아도 된다."]},{"cell_type":"code","execution_count":118,"id":"28053219","metadata":{"id":"28053219","executionInfo":{"status":"ok","timestamp":1720451935495,"user_tz":-540,"elapsed":1,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["x = tc.tensor(1.)\n","y = tc.tensor(2., requires_grad=True)"]},{"cell_type":"code","execution_count":119,"id":"29c2bac7","metadata":{"id":"29c2bac7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720451941517,"user_tz":-540,"elapsed":537,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"0dac11d0-9f03-4725-fc71-6fcfd4f1a42e"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(2., grad_fn=<MulBackward0>)\n","tensor(2., grad_fn=<MulBackward0>)\n"]}],"source":["F = x * y\n","print(F)\n","F.backward()\n","print(F)"]},{"cell_type":"code","execution_count":125,"id":"0ba47cc3","metadata":{"id":"0ba47cc3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720452027941,"user_tz":-540,"elapsed":3,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"6bc9c7ea-ac2d-42d7-b485-05adaec7860f"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-125-1d2db2814d4a>:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n","  F.grad\n"]}],"source":["F.grad"]},{"cell_type":"code","execution_count":121,"id":"6fb9cb00","metadata":{"id":"6fb9cb00","executionInfo":{"status":"ok","timestamp":1720451995558,"user_tz":-540,"elapsed":568,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["x.grad"]},{"cell_type":"code","execution_count":123,"id":"9355969c","metadata":{"id":"9355969c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720452005021,"user_tz":-540,"elapsed":542,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"b487bb24-5b7f-4919-b24d-866f9d642ac0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":123}],"source":["y.grad"]},{"cell_type":"markdown","id":"47018679","metadata":{"id":"47018679"},"source":["추가적으로, 상수 텐서만으로 정의된 텐서의 경우에는 어떤 연산을 적용하더라도 상수 텐서가 생성된다. 따라서, 이렇게 얻은 상수 텐서에 대해서는 .backward() 메서드는 에러를 발생시킨다."]},{"cell_type":"code","execution_count":126,"id":"9be9f9c8","metadata":{"id":"9be9f9c8","executionInfo":{"status":"ok","timestamp":1720452042604,"user_tz":-540,"elapsed":534,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["x = tc.tensor(1.)\n","y = tc.tensor(2.)\n","F = x + y"]},{"cell_type":"code","execution_count":127,"id":"ae6005a5","metadata":{"id":"ae6005a5","colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"status":"error","timestamp":1720452044313,"user_tz":-540,"elapsed":4,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"8716d5d1-87f0-4293-8121-e98af0f3b015"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"element 0 of tensors does not require grad and does not have a grad_fn","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-127-99ea150b60f8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}],"source":["F.backward()"]},{"cell_type":"code","execution_count":128,"id":"d2b85dc5","metadata":{"id":"d2b85dc5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720452049617,"user_tz":-540,"elapsed":551,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"353b6e41-7adc-402b-dedd-0d72a6c97387"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":128}],"source":["F.grad is None"]},{"cell_type":"markdown","id":"b10bbdab","metadata":{"id":"b10bbdab"},"source":["### Step 3. 다차원 텐서의 자동미분 실행하기"]},{"cell_type":"markdown","id":"5989cb5b","metadata":{"id":"5989cb5b"},"source":["#### 다차원 텐서에 대해 정의된 함수에서의 자동미분"]},{"cell_type":"markdown","id":"95ac6652","metadata":{"id":"95ac6652"},"source":["지금까지는 하나의 스칼라 변수로 이루어진 0차원 텐서에 대해 정의된, 간단한 함수에 대해서만 자동미분을 실행해보았다. 그런데 텐서 객체는 다차원의 배열을 나타낼 수 있다. 따라서 다차원 텐서에 대해 정의된 함수에서 자동미분이 실행되는 방법을 알면 계산을 편리하게 할 수 있다.\n","\n","다차원 텐서와 관련된 .grad 속성을 어떻게 해석해야 할까? 한마디로 표현하면, 텐서의 각 원소를 스칼라 값 변수로 해석하면 된다. 즉, 다차원 텐서를 스칼라 변수들의 집합으로 보면 된다."]},{"cell_type":"markdown","id":"88c0e308","metadata":{"id":"88c0e308"},"source":["이렇게만 말해서는 이해가 잘 가지 않을 것이다. 다음과 같은 계산을 통해 자세히 알아보자."]},{"cell_type":"code","execution_count":130,"id":"c211a0be","metadata":{"id":"c211a0be","executionInfo":{"status":"ok","timestamp":1720452298939,"user_tz":-540,"elapsed":553,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["tensor = tc.tensor([2.0, 4.0, 8.0], requires_grad=True)\n","arr = tc.tensor([-1.0, 2.0, 0], requires_grad=True)\n","F = (arr * tensor ** 2).sum()\n","F.backward()"]},{"cell_type":"markdown","id":"b9a0d070","metadata":{"id":"b9a0d070"},"source":["위의 코드에서 정의된 함수 F를 풀어서 쓰면 $F = -1\\:(x_0)^2 + 2\\:(x_1)^2 + 0\\:(x_2)^2$이다. 그리고 다차원 텐서의 각 원소를 스칼라 값 변수로 해석한다는 것은, $\\mathrm{tensor} = [x_0, x_1, x_2]$로 보겠다는 뜻이다."]},{"cell_type":"markdown","id":"afbb87af","metadata":{"id":"afbb87af"},"source":["이때, tensor.grad에는 어떤 값이 저장되어야 타당할까? tensor의 각 스칼라 변수들로 편미분한 값들을 tensor와 같은 shape의 배열로 저장하면 좋을 것이다."]},{"cell_type":"markdown","id":"1fc1254d","metadata":{"id":"1fc1254d"},"source":["\\begin{align}\n","{\\nabla}F &= \\big[\\frac{\\partial F}{\\partial x_0},\\frac{\\partial F}{\\partial x_1},\\frac{\\partial F}{\\partial x_2}\\big]\\\\\n","&= \\big[-2x_0,\\:4x_1,\\:0x_2\\big]\\\\\n","{\\nabla}F\\big|_{x_0=2, x_1=4, x_2=8} &= \\big[-4,\\:16,\\:0\\big]\n","\\end{align}"]},{"cell_type":"markdown","id":"cd9e4e53","metadata":{"id":"cd9e4e53"},"source":["실제로 tensor.grad 는 tensor에 저장된 특정 값에서의 ${\\nabla}F$ 를 저장한다. 다음 코드를 실행하여 확인해보자."]},{"cell_type":"code","execution_count":131,"id":"ff494ccb","metadata":{"id":"ff494ccb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720452304283,"user_tz":-540,"elapsed":1060,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"8db602be-b536-4853-b503-bf0d05b9f89f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-4., 16.,  0.])"]},"metadata":{},"execution_count":131}],"source":["tensor.grad"]},{"cell_type":"markdown","id":"6637697f","metadata":{"id":"6637697f"},"source":["일반화하여 표현하면 다음과 같다. tensor의 각 원소는 스칼라 값 변수로 해석할 수 있고, tensor.grad에서 대응되는 위치의 요소는 해당 변수에 대한 미분계수이다.\n","\n","$\\text{tensor}[x_0, \\dots, x_{(N-1)}] \\rightarrow \\text{tensor.grad}[x_0, \\dots, x_{(N-1)}] = {\\nabla}F = \\big[\\frac{\\partial F}{\\partial x_0},\\dots,\\frac{\\partial F}{\\partial x_{(N-1)}}\\big]$"]},{"cell_type":"markdown","id":"9b333799","metadata":{"id":"9b333799"},"source":["#### 벡터화된 자동미분"]},{"cell_type":"markdown","id":"c4eca391","metadata":{"id":"c4eca391"},"source":["방금 다차원 텐서에 의해 정의된 스칼라 함수에 대한 자동미분에 대해 배웠다. 이번에는 스칼라 함수가 아닌, 벡터 함수에 대해 자동미분을 실행할 때는 어떻게 실행되는지 알아보자.\n","\n",".backward() 메서드를 호출한 최종 함수가 스칼라가 아니라 벡터 함수라면, PyTorch는 최종 함수를 스칼라로 다 합친 후에 역전파를 진행해야한다.\n","\n","이렇게 합친 $\\sum F$는 스칼라이기 때문에 $\\frac{\\partial (\\sum F)}{\\partial x_{i}}$ 또한 스칼라이다. 따라서 위에서 살펴본 바와 같이 tensor와 tensor.grad는 항상 같은 shape을 갖는다.\n","\n","이렇게만 말해서는 이해가 가지 않으니, 다음과 같은 계산을 통해 알아보자."]},{"cell_type":"code","execution_count":136,"id":"43a7cb94","metadata":{"id":"43a7cb94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720452761779,"user_tz":-540,"elapsed":700,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"270f3f85-f464-4f31-fd4a-fc5fe098f841"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-10.0000,  -8.9474,  -7.8947,  -6.8421,  -5.7895,  -4.7368,  -3.6842,\n","         -2.6316,  -1.5789,  -0.5263,   0.5263,   1.5789,   2.6316,   3.6842,\n","          4.7368,   5.7895,   6.8421,   7.8947,   8.9474,  10.0000])"]},"metadata":{},"execution_count":136}],"source":["tensor = tc.linspace(-5, 5, 20, requires_grad=True)\n","F = tensor ** 2  # shape-(20)인 텐서\n","F_sum = F.sum()\n","F_sum.backward()\n","# F.backward()\n","tensor.grad"]},{"cell_type":"markdown","id":"6d4fce29","metadata":{"id":"6d4fce29"},"source":["위의 코드에서 정의된 함수 F는 $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$이다. 그리고 PyTorch에서 F_sum.backward()를 실행할 때 이를 스칼라로 다 합친다는 것은, $\\sum {F} = x_0 ^2 + \\dots + x^2_{99}$로 합친 후 이에 대해 .backward()를 실행하겠다는 뜻이다."]},{"cell_type":"markdown","id":"2f3bc6ee","metadata":{"id":"2f3bc6ee"},"source":["그런데 여기서 의문이 생긴다. 다변수 벡터함수 $F$의 편미분 계수들을 구하기 위해서는 야코비 행렬을 구하는 게 합당해 보인다. 그런데 $\\sum F$에 대해 .backward()를 실행시키는 것은 매우 다른 결과를 불러온다.\n","\n","각 성분함수에 대한 편미분 계수들을 일일이 구하지 못하고, 대신 성분함수들의 합에 대한 편미분 계수 $\\frac{\\partial (F_0+F_1+ \\cdots + F_{N-1})}{\\partial x_i}$ 만을 구하게 된다."]},{"cell_type":"markdown","id":"85f872b3","metadata":{"id":"85f872b3"},"source":["왜 PyTorch에서는 자동미분 기능을 이렇게 구현한 것일까? 만약 다변수 벡터함수 의 각 성분함수들이 각각 독립인 입력 변수에 대해 정의되었다면, 즉 독립인 $x_0, x_1,\\cdots, x_{(N-1)}$ 에 대해 $F=[F_0(x_0), F_1(x_1), \\cdots, F_{N-1}(x_{(N-1)})]$ 로 정의되었다면 $\\sum F$에 대해 .backward()를 실행시키는 것은 의미있는 행위가 된다. 유효한 모든 편미분 계수를 $\\big[\\frac{\\partial F_{0}}{\\partial x_0},\\dots,\\frac{\\partial F_{N-1}}{\\partial x_{(N-1)}}\\big]$ 와 같이 구할 수 있게 되기 때문이다."]},{"cell_type":"markdown","id":"67aadde5","metadata":{"id":"67aadde5"},"source":["다시 위의 예시로 돌아가보자.  $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$에 대해 .backward()를 실행시킨 것은  $\\sum{F} = x_0 ^2 + \\dots + x^2_{99}$에 대해 .backward()를 실행시킨 것과 같다. 그리고 이후에 입력 tensor $\\rm\\textbf{x} = \\big[ x_0, x_1,\\cdots, x_{(N-1)}\\big]$ 에 대한 tensor.grad를 구하면 입력 tensor $\\rm\\textbf{x}$와 shape이 동일한 ${\\nabla}(\\Sigma{{F}}) = \\big[2x_0,\\ \\dots, \\; 2x_{99} \\big]$ 가 구해진다."]},{"cell_type":"markdown","id":"94d7fc45","metadata":{"id":"94d7fc45"},"source":["이 계산은 결국, 100개의 독립적인 값들에 대해 함수 $f(x) = x ^ 2$ 의 편미분계수 값 ($\\frac{\\mathrm{d}f}{\\mathrm{d}x} = 2x$)을 한번에 계산한 것과 같았다. 따라서, PyTorch를 이용하여 독립적인 값들에 대한 성분함수로 이루어진 다변수 벡터 함수의 미분을 구하는 기능은, 여러 개의 독립적인 데이터를 하나의 텐서로 묶어서 동일한 계산을 한 번에 수행할 때 큰 이점이 있다. 신경망에 대해 배우고 본격적인 딥러닝에 대해 실습할 때 도움이 될 것이다."]},{"cell_type":"markdown","id":"b44d37d0","metadata":{"id":"b44d37d0"},"source":["### 문제: 도함수의 그래프 그리기\n","\n",".backward() 메서드를 이용하면 특정 점에서의 그래디언트만 구할 수 있고, 도함수의 식과 그래프는 알 수 없다. 그런데, 벡터화된 자동미분을 이용하면 여러 점에서의 편미분계수 값을 한번에 구할 수 있으므로, matplotlib을 통해 그래프를 찍을 수 있게 된다.\n","\n","1. 벡터화된 자동미분을 수행하는 다음의 함수를 완성해보자. matplotlib에 관한 실습1의 내용을 잘 떠올리면서 작성해보자. (주의: matplotlib에 데이터를 전달할 때는 torch의 텐서가 아닌, 널리 알려진 라이브러리인 NumPy의 배열을 사용하는 것이 좋습니다.)"]},{"cell_type":"markdown","source":[" $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$의 그래프와 그 도함수를 torch를 이용해서 그려보자."],"metadata":{"id":"n-UzYgKBZkV9"},"id":"n-UzYgKBZkV9"},{"cell_type":"code","execution_count":156,"id":"63b190cf","metadata":{"id":"63b190cf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720453674943,"user_tz":-540,"elapsed":562,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"b87b8c31-86c7-42a9-8f85-4369e646c62b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([ 0.0000,  0.0020,  0.0040,  ..., -0.0273, -0.0273, -0.0273],\n","        grad_fn=<MulBackward0>),\n"," tensor([2.0000, 1.9987, 1.9973,  ..., 0.0021, 0.0022, 0.0024]))"]},"metadata":{},"execution_count":156}],"source":["x = tc.linspace(0, 10, 10000, requires_grad=True)\n","f = tc.sin(2*x)*tc.cos(x)*tc.exp(-x/3)\n","f_sum = f.sum()\n","f_sum.backward()\n","f, x.grad\n"]},{"cell_type":"code","execution_count":169,"id":"a956957d","metadata":{"id":"a956957d","executionInfo":{"status":"ok","timestamp":1720453945997,"user_tz":-540,"elapsed":614,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def plot_func_and_deriv(x):\n","    \"\"\"\n","    함수 func(x)와 도함수 dfunc/dx를 같은 축(axis) 상에 그리는 함수\n","\n","    매개변수 (Parameters)\n","    ----------\n","    x : PyTorch.Tensor, shape-(N,)\n","        함수 func(x)와 도함수 dfunc/dx를 그리는 x의 정의역\n","\n","    func: Callable[[Tensor], Tensor]\n","        x에 대한 일변수 함수\n","\n","    반환 값 (Returns)\n","    -------\n","    Tuple[Figure, Axis]\n","        matplotlib로 그래프를 그리기 위한 fig와 ax\n","    \"\"\"\n","    x = tc.tensor(x, requires_grad=True)\n","    y = f(x)\n","    y_sum = y.sum()\n","    y_sum.backward()\n","\n","    # 여기에 코드 작성\n","    fig, ax = plt.subplots()\n","    ax.plot(x.detach().numpy(), y.detach().numpy(), c=\"red\")\n","    ax.plot(x.detach().numpy(), x.grad.detach().numpy(), c=\"blue\")\n","    ax.grid(True)\n","\n","    return fig, ax"]},{"cell_type":"markdown","id":"6565d15f","metadata":{"id":"6565d15f"},"source":["2. 이제 위에서 작성한 함수를 이용하여 구간 $[0, 10]$를 균등하게 10,000개로 나눈 정의역에 대해 함수 $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$와 그 도함수의 그래프를 그려보자."]},{"cell_type":"code","execution_count":170,"id":"72733202","metadata":{"id":"72733202","executionInfo":{"status":"ok","timestamp":1720453947942,"user_tz":-540,"elapsed":1,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["def f(x):\n","    f= tc.sin(2*x)*tc.cos(x)*tc.exp(-x/3)\n","    return f"]},{"cell_type":"code","execution_count":171,"id":"7c5f677e","metadata":{"id":"7c5f677e","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1720453949909,"user_tz":-540,"elapsed":4,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"4dc0de93-2293-4f17-80ae-b2389cdb0540"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-169-b3a4486f8f2c>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  x = tc.tensor(x, requires_grad=True)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["x = tc.linspace(0, 10, 10000)\n","fig, ax = plot_func_and_deriv(x)"]},{"cell_type":"markdown","id":"c0a1f72a","metadata":{"id":"c0a1f72a"},"source":["### Step 4. Torch의 자동미분을 이용한 경사하강법"]},{"cell_type":"markdown","id":"72b0de77","metadata":{"id":"72b0de77"},"source":["#### 경사하강법 코드 수정하기 (1)"]},{"cell_type":"markdown","id":"6a2062d0","metadata":{"id":"6a2062d0"},"source":["자동미분을 이용하면 경사하강법을 쉽게 구현할 수 있다. 연습을 위해 간단한 일변수 함수에 대해 경사하강법을 수행해볼 것이다. 앞선 예제에서도 다룬적 있는 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n","\n","앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_parabola()를 작성해보았다.\n","\n","```python\n","def descent_down_parabola(w_start, learning_rate, num_steps):\n","    w_values = [w_start]\n","    for _ in range(num_steps):\n","        w_old = w_values[-1]\n","        w_new = w_old - learning_rate * (2 * w_old)\n","        w_values.append(w_new)\n","    return np.array(w_values)\n","```\n","\n","이번에는 도함수를 모르는 $\\mathscr{L}(w)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. $w$의 값을 PyTorch 텐서로 저장한 후, $\\mathscr{L}(w)$를 $w$의 식으로 정의해주어, .backward() 메서드를 사용하여 편미분계수를 구할 수 있다.\n","\n","아래의 경사하강법 공식에 따라 자동미분을 이용한 경사하강법을 프로그래밍으로 구현해보자.\n","\n","\\begin{equation}\n","w_{\\mathrm{new}} = w_{\\mathrm{old}} - \\delta \\frac{\\mathrm{d}\\mathscr{L}}{\\mathrm{d}w}\\big|_{w_{\\mathrm{old}}}\n","\\end{equation}"]},{"cell_type":"markdown","id":"2da681a1","metadata":{"id":"2da681a1"},"source":["다음과 같이 $w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."]},{"cell_type":"code","execution_count":175,"id":"941881f8","metadata":{"id":"941881f8","executionInfo":{"status":"ok","timestamp":1720454183941,"user_tz":-540,"elapsed":607,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["w = tc.tensor([10.0], requires_grad=True)\n","learning_rate = 0.3\n","num_steps = 20"]},{"cell_type":"markdown","id":"64bfcec4","metadata":{"id":"64bfcec4"},"source":["이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n","```\n","Tensor(4.)\n","Tensor(1.6)\n","Tensor(0.64)\n","Tensor(0.256)\n","Tensor(0.1024)\n","```"]},{"cell_type":"code","execution_count":176,"id":"7fda26a0","metadata":{"id":"7fda26a0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720454187016,"user_tz":-540,"elapsed":540,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"7d0bfd53-8024-455e-88f3-3854ec224984"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([4.], requires_grad=True)\n","tensor([1.6000], requires_grad=True)\n","tensor([0.6400], requires_grad=True)\n","tensor([0.2560], requires_grad=True)\n","tensor([0.1024], requires_grad=True)\n","tensor([0.0410], requires_grad=True)\n","tensor([0.0164], requires_grad=True)\n","tensor([0.0066], requires_grad=True)\n","tensor([0.0026], requires_grad=True)\n","tensor([0.0010], requires_grad=True)\n","tensor([0.0004], requires_grad=True)\n","tensor([0.0002], requires_grad=True)\n","tensor([6.7109e-05], requires_grad=True)\n","tensor([2.6844e-05], requires_grad=True)\n","tensor([1.0737e-05], requires_grad=True)\n","tensor([4.2950e-06], requires_grad=True)\n","tensor([1.7180e-06], requires_grad=True)\n","tensor([6.8719e-07], requires_grad=True)\n","tensor([2.7488e-07], requires_grad=True)\n","tensor([1.0995e-07], requires_grad=True)\n"]}],"source":["for _ in range(num_steps):\n","    ℒ = w ** 2\n","    ℒ.backward()\n","    # 여기에 코드 작성\n","\n","    #  블록 안에서 w를 업데이트. 이는 PyTorch가 이 블록 내의 연산을 추적하지 않도록 한다.\n","    with tc.no_grad():\n","        w.data -= learning_rate * w.grad\n","    #w의 그래디언트를 초기화. 이를 통해 다음 단계에서 그래디언트가 누적되지 않도록 한다.\n","    w.grad = None\n","\n","    print(w)"]},{"cell_type":"markdown","id":"604b8e15","metadata":{"id":"604b8e15"},"source":["그런데 코드를 작성할 때, 한가지 생각해볼만한 부분이 있다. 위의 코드를 완성하여 원하는 출력값도 제대로 얻었다면, 아래의 두 코드와 자신의 답변을 비교해보자. 꼭 먼저 코드를 직접 작성해본 후에 답변을 확인하길 바란다.\n","\n","다음의 두 코드는 모두 원하는 출력값을 얻게 해주는 코드이다.\n","첫번째 코드는 다음과 같다.\n","```python\n","w = w - learning_rate * w.grad\n","```\n","두번째 코드는 다음과 같다.\n","```python\n","w.data -= learning_rate * w.grad\n","```"]},{"cell_type":"markdown","id":"205b2767","metadata":{"id":"205b2767"},"source":["두 코드는 동일한 출력값을 얻게 해줄 뿐 아니라, 사실상 같은 의미라고 느껴진다. 그리고 첫번째 코드가 우리가 알고 있는 공식에 더 가까원 형태이기 때문에 좀 더 직관적이다. 그러나, 두번째 코드는 두가지 이점이 있다.\n","\n","첫째로 컴퓨터 계산 속도를 최적화할 수 있다. 앞서 PyTorch의 텐서는 NumPy 배열의 수학적 연산들을 추적하는 추가 기능을 갖고 있는 객체라는 것을 배웠다. 그러나 이렇게 수학 연산을 추적하는 과정이 w 값을 갱신하는 과정에서는 굳이 필요하지 않다. 따라서 첫번째 코드와 같이 텐서를 사용하면, 불필요한 수학 연산의 추적으로 인해 간접적인 연산 처리 시간인 오버헤드(overhead)만 발생한다. 그러나 두번째 코드에서는 직접 텐서의 데이터를 업데이트함으로써, 불필요한 연산 그래프 추적을 피한다.\n","\n","둘째로 추가적인 메모리 공간을 필요로 하지 않는다. 연산자 '-='는 증강 업데이트(augmented update)를 실행하는 연산자이다. 이는 컴퓨터가 새로운 메모리 공간을 할당하여 배열의 값을 교체하는 대신, 사용하던 메모리 공간을 그대로 다시 덮어쓰는 것을 의미한다. 따라서 기존 메모리 공간을 그대로 사용하므로, 메모리 사용이 최적화된다.\n","\n","조만간 신경망에 대해 배운 후, 어렵고 복잡한 수학적 함수의 파라미터를 조정하게 되면, 수많은 대규모 데이터를 업데이트하게 될 것이다. 이런 상황에서 위의 두가지 이점은 학습의 성능에 큰 차이를 만들 것이다."]},{"cell_type":"markdown","id":"606ef82a","metadata":{"id":"606ef82a"},"source":["#### 경사하강법 코드 수정하기 (2)"]},{"cell_type":"markdown","id":"cf2419b9","metadata":{"id":"cf2419b9"},"source":["이번에는 앞선 예제에서 다룬적 있는 이변수 함수 $\\mathscr{L}(w_1, w_2) = 2w_1^2 + 3w_2^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n","\n","앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_2d_parabola()를 작성해보았다.\n","\n","```python\n","def descent_down_2d_parabola(w_start, learning_rate, num_steps):\n","    xy_values = [w_start]\n","    for _ in range(num_steps):\n","        xy_old = xy_values[-1]\n","        xy_new = xy_old - learning_rate * (np.array([4., 6.]) * xy_old)\n","        xy_values.append(xy_new)\n","    return np.array(xy_values)\n","```\n","\n","이번에는 도함수를 모르는 $\\mathscr{L}(w_1, w_2)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. 다차원 텐서로 정의된 함수의 자동미분을 잘 떠올리면 해결하는 데 도움이 될 것이다."]},{"cell_type":"markdown","id":"f0657ae3","metadata":{"id":"f0657ae3"},"source":["다음과 같이 $\\rm\\textbf w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."]},{"cell_type":"code","execution_count":177,"id":"8ff9d793","metadata":{"id":"8ff9d793","executionInfo":{"status":"ok","timestamp":1720454437699,"user_tz":-540,"elapsed":716,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["w = tc.tensor([2., 4.], requires_grad=True)\n","learning_rate = 0.1\n","num_steps = 30"]},{"cell_type":"markdown","id":"c03fd2c5","metadata":{"id":"c03fd2c5"},"source":["이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w_1=0, w_2=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n","```\n","Tensor([1.2, 1.6])\n","Tensor([0.72, 0.64])\n","Tensor([0.432, 0.256])\n","Tensor([0.2592, 0.1024])\n","Tensor([0.15552, 0.04096])\n","```"]},{"cell_type":"code","execution_count":178,"id":"6dc9819f","metadata":{"id":"6dc9819f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720454521382,"user_tz":-540,"elapsed":562,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"05c0746b-3111-4f23-eb73-450ce2849ed6"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.2000, 1.6000], requires_grad=True)\n","tensor([0.7200, 0.6400], requires_grad=True)\n","tensor([0.4320, 0.2560], requires_grad=True)\n","tensor([0.2592, 0.1024], requires_grad=True)\n","tensor([0.1555, 0.0410], requires_grad=True)\n","tensor([0.0933, 0.0164], requires_grad=True)\n","tensor([0.0560, 0.0066], requires_grad=True)\n","tensor([0.0336, 0.0026], requires_grad=True)\n","tensor([0.0202, 0.0010], requires_grad=True)\n","tensor([0.0121, 0.0004], requires_grad=True)\n","tensor([0.0073, 0.0002], requires_grad=True)\n","tensor([4.3536e-03, 6.7109e-05], requires_grad=True)\n","tensor([2.6121e-03, 2.6844e-05], requires_grad=True)\n","tensor([1.5673e-03, 1.0737e-05], requires_grad=True)\n","tensor([9.4037e-04, 4.2950e-06], requires_grad=True)\n","tensor([5.6422e-04, 1.7180e-06], requires_grad=True)\n","tensor([3.3853e-04, 6.8719e-07], requires_grad=True)\n","tensor([2.0312e-04, 2.7488e-07], requires_grad=True)\n","tensor([1.2187e-04, 1.0995e-07], requires_grad=True)\n","tensor([7.3123e-05, 4.3980e-08], requires_grad=True)\n","tensor([4.3874e-05, 1.7592e-08], requires_grad=True)\n","tensor([2.6324e-05, 7.0369e-09], requires_grad=True)\n","tensor([1.5795e-05, 2.8147e-09], requires_grad=True)\n","tensor([9.4768e-06, 1.1259e-09], requires_grad=True)\n","tensor([5.6861e-06, 4.5036e-10], requires_grad=True)\n","tensor([3.4116e-06, 1.8014e-10], requires_grad=True)\n","tensor([2.0470e-06, 7.2058e-11], requires_grad=True)\n","tensor([1.2282e-06, 2.8823e-11], requires_grad=True)\n","tensor([7.3691e-07, 1.1529e-11], requires_grad=True)\n","tensor([4.4215e-07, 4.6117e-12], requires_grad=True)\n"]}],"source":["const = tc.tensor([2.0, 3.0])\n","for _ in range(num_steps):\n","    ℒ = const * w ** 2\n","    ℒ.sum().backward()\n","    # 여기에 코드 작성\n","\n","    # w 업데이트 (메모리 최적화)\n","    with tc.no_grad():\n","        w.data -= learning_rate * w.grad\n","\n","    # w 값 출력\n","    print(w)\n","\n","    # 그래디언트 초기화\n","    w.grad.zero_()"]},{"cell_type":"markdown","id":"8f86fbb1","metadata":{"id":"8f86fbb1"},"source":["#### 일반적인 경사하강법 함수 작성하기"]},{"cell_type":"markdown","id":"633555d6","metadata":{"id":"633555d6"},"source":["일변수 함수, 다변수 함수에 대해 경사하강법을 수행해보았으니, 보편적인 상황에 대해 적용할 수 있는 일반적인 경사하강법 함수를 작성하는 것만 남았다."]},{"cell_type":"markdown","id":"78175514","metadata":{"id":"78175514"},"source":["<문제: 일반적인 경사하강법 함수 작성하기>\n","\n","이 문제의 목표는 어떤 함수가 어떤 텐서로 정의되어 있는지에 상관없이 사용할 수 있는 경사하강법 함수를 작성하는 것이다. 함수 외부에서 텐서와 텐서들로 정의된 함수를 모두 정의한 후, .backward() 메서드까지 실행한다. 함수 내부로는 텐서들만 전달해주어, 함수 내에서는 그 텐서들을 이용하여 경사하강법을 실행한다."]},{"cell_type":"markdown","id":"4d8ac2fb","metadata":{"id":"4d8ac2fb"},"source":["아래 함수의 주석을 잘 보고, 일반적인 경사하강법 함수를 작성해보자. 주석을 보면 이 함수는 단일 텐서를 인자로 입력받을 수도 있지만, 여러개의 텐서로 이루어진 iterable한 객체를 입력받을 수도 있다. 어떻게 코딩해야 할지 막막한 느낌이 든다면, 다음 힌트를 살펴보자.\n","\n","> HINT\n","> 1. 여러 개의 텐서로 이루어진 iterable한 자료형이 들어올 수 있으므로, for문을 이용하여 텐서를 하나씩 꺼내며 경사하강하는 코드를 작성해야한다.\n","> 2. 단일 텐서가 들어오면 for문을 이용할 수 없으므로, 단일 텐서를 단일 텐서가 들어있는 리스트로 바꾸어주는 과정이 있어야 한다."]},{"cell_type":"code","execution_count":179,"id":"db9666b8","metadata":{"id":"db9666b8","executionInfo":{"status":"ok","timestamp":1720455033949,"user_tz":-540,"elapsed":624,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["def gradient_step(tensors, learning_rate):\n","    \"\"\"\n","    경사하강법의 공식에 따라 gradient-step을 실행.\n","\n","    매개변수 (Parameters)\n","    ----------\n","    tensors : Union[Tensor, Iterable[Tensors]]\n","        단일 텐서, 혹은 텐서로 이루어진 iterable(리스트, 튜플 등) 모두 가능\n","        만약 특정 tensor에 대한 `tensor.grad`가 `None`인 경우, 업데이트를 건너 뜀\n","\n","    learning_rate : float\n","        매 gradient-step에서의 학습률. 양수\n","\n","    참고\n","    -----\n","    함수에서 진행되는 모든 gradient-steps는 tensor 내에서 바로 반영되므로, 반환 값 없음\n","    \"\"\"\n","    # isinstance 함수를 이용하여 입력된 tensors가 단일 텐서인지, iterable인지 판단한다\n","    if isinstance(tensors, tc.Tensor):\n","        tensors = [tensors]\n","\n","    # Only one tensor was provided. Pack\n","    # it into a list so it can be accessed via\n","    # iteration\n","    # for 문을 이용하여 tensors의 tensor를 하나씩 꺼내며 경사하강을 진행\n","    # 여기에 코드 작성\n","    for tensor in tensors:\n","      if tensor.grad is not None:\n","        tensor.data -= learning_rate * tensor.grad\n","        tensor.grad.zero_()"]},{"cell_type":"markdown","id":"63edb99a","metadata":{"id":"63edb99a"},"source":["앞서 수행했던 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 다시 한번 실행해봄으로써 보편적인 경사하강법 함수가 우리가 원하는대로 동작하는지 확인해보자."]},{"cell_type":"code","execution_count":180,"id":"fbf280d6","metadata":{"id":"fbf280d6","executionInfo":{"status":"ok","timestamp":1720455064267,"user_tz":-540,"elapsed":552,"user":{"displayName":"김지환","userId":"12253807925966887294"}}},"outputs":[],"source":["w = tc.tensor(10.0, requires_grad=True)\n","learning_rate = 0.3\n","num_steps = 5"]},{"cell_type":"code","execution_count":181,"id":"9abee228","metadata":{"id":"9abee228","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720455065917,"user_tz":-540,"elapsed":2,"user":{"displayName":"김지환","userId":"12253807925966887294"}},"outputId":"fc7c6900-457a-40b0-8602-519fbaf24115"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(4., requires_grad=True)\n","tensor(1.6000, requires_grad=True)\n","tensor(0.6400, requires_grad=True)\n","tensor(0.2560, requires_grad=True)\n","tensor(0.1024, requires_grad=True)\n"]}],"source":["for _ in range(num_steps):\n","    ℒ = w ** 2\n","    ℒ.backward()\n","    gradient_step(w, learning_rate)\n","    print(w)"]},{"cell_type":"markdown","id":"99313c60","metadata":{"id":"99313c60"},"source":["### 배운 내용 되돌아보기"]},{"cell_type":"markdown","id":"cecca3d9","metadata":{"id":"cecca3d9"},"source":["이번 실습에서는 자동미분을 도와주는 PyTorch 라이브러리의 사용법을 배우고 익혔다. PyTorch는 앞으로의 거의 모든 실습에서 사용되는 중요한 라이브러리이다.\n","\n","- Tensor를 생성하는 여러 가지 함수들을 사용해보았다. 원소를 직접 적어줄 수도 있고, 리스트, 튜플, NumPy의 ndarray 등으로부터 Tensor를 생성할 수도 있었다.\n","\n","- 기존에 생성된 Tensor의 행과 열을 자유자재로 바꾸거나 일부 행이나 열만 슬라이싱 해보았다.\n","\n","- PyTorch에서 제공하는 다양한 수학 연산 함수들을 사용해보았다. 그 과정에서 NumPy의 함수들과의 유사성을 확인하였다.\n","\n","- 선형대수 연산을 돕는 함수인 matmul()과 einsum()을 사용해보았다.\n","\n","- PyTorch에 딥러닝을 위한 특수 함수들이 다양하게 존재함을 알게 되었으나, 사용해보지는 않았다.\n","\n","- PyTorch 텐서 객체의 .backward() 메서드를 사용하여 자동미분을 실행하고, 텐서의 .grad 속성을 이용하여 편미분 계수를 구해보았다.\n","\n","- 경사하강을 반복하며 최적의 모델을 찾아갈 때, 경사하강이 1회 종료될 때마다 기존의 편미분 계수를 폐기해주어야 함을 알게 되었다. 이를 위해 .grad 속성을 폐기하는 방법을 직접 사용해보았다.\n","\n","- PyTorch 텐서와 NumPy의 배열 사이의 관계를 알게 되었다.\n","\n","- 불필요한 편미분 계수를 계산하는 것을 방지하기 위해, 텐서를 상수 취급하는 방법을 도입해야 함을 알게 되었다. 그리고 텐서를 상수 취급하기 위한 방법을 사용해보았다.\n","\n","- 다차원 텐서에 대해 정의된 함수 (다변수 함수)에서 자동미분을 실행하면 다차원 텐서의 각 원소가 스칼라 값 변수로 해석되어 자동미분이 이루어짐을 알게 되었다. 또한 다차원 텐서의 .grad 속성에 함수의 그래디언트 값이 저장됨을 확인하였다.\n","\n","- 다변수 벡터 함수에 대해 자동미분을 실행하면 모든 성분함수를 합한 것에 대해 자동미분이 이루어짐을 알게 되었다. 또한 이런 규칙이 어떤 유용함을 가지는지 확인하였다.\n","\n","- PyTorch의 자동미분을 이용하여 경사하강법 함수를 새롭게 구현해보았다."]},{"cell_type":"code","execution_count":null,"id":"649f5f3b","metadata":{"id":"649f5f3b"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}